{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOfbDP7IIl07wD2KV2oxhFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliuserbach/Semantic-Features/blob/master/Object_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs68tbFdNJd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# install dependencies: (use cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwdlDhK9NRAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# install detectron2:\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLrTotbPMz3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBJRuzxNM8YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data/Results\n",
        "\n",
        "DATA_DIR=\"data/leftImg8bit/train_extra/schweinfurt\"\n",
        "SAVE_DIR=\"data/Results\"\n",
        "\n",
        "model_file=\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
        "cfg = get_cfg()\n",
        "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
        "cfg.merge_from_file(model_zoo.get_config_file(model_file))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_file)\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "\n",
        "images_path = list(glob.iglob(os.path.join(DATA_DIR, '*.*')))\n",
        "n_images = len(images_path)\n",
        "i = 0\n",
        "# create empty dictionary \n",
        "features = {}\n",
        "# create empty list of the results\n",
        "features['results'] = []\n",
        "\n",
        "for image_path in images_path:\n",
        "  # Load image from path\n",
        "  image = cv2.imread(image_path)\n",
        "  # Predict bounding boxes and classes\n",
        "  results = predictor(image)\n",
        "  print(\"Image number:{} of {} is beeing processed\".format(i+1, n_images))\n",
        "\n",
        "  # Save visualization in path DATA_DIR/Results with same name as images\n",
        "  v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "  v = v.draw_instance_predictions(results[\"instances\"].to(\"cpu\"))\n",
        "  head, tail = os.path.split(image_path)\n",
        "  name = os.path.join(SAVE_DIR,\"{}\".format(tail))\n",
        "  cv2.imwrite(name, v.get_image()[:, :, ::-1])\n",
        "\n",
        "  # export classes and bounding boxes\n",
        "  classes_tensor = results[\"instances\"].pred_classes\n",
        "  boxes_tensor = results[\"instances\"].pred_boxes\n",
        "  classes = classes_tensor.cpu().tolist()\n",
        "  boxes = []\n",
        "  box = boxes_tensor.to(\"cpu\").tensor.tolist()\n",
        "  # put them in a dicitonary to later save them into a json file\n",
        "  features['results'].append({'image_id': tail, 'classes': classes, 'boxes': box})\n",
        "  i +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qec01xIiNCL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write to json file\n",
        "import json\n",
        "# format: row: image_id , [class_ids], [boxes] , with boxes as x1, y1, x2, \n",
        "FEATURE_FILE = 'results.json'\n",
        "with open(FEATURE_FILE, 'w') as outfile:\n",
        "    json.dump(features, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}